---
date: 2025-11-23T22:19:49+0000
author: Robert Welborn
git_commit: fc96e5267179e423c6eec3b04571f1d8fdb6c0ef
branch: feature/issues-27-29-logging-output-formatting
repository: datablogin/PaidSocialNav
topic: "FastMCP Remote Server Implementation Plan (Phased)"
tags: [plan, mcp, fastmcp, deployment, cloud-run, architecture]
status: draft
related_research: thoughts/shared/research/2025-11-22-claude-skills-mcp-architecture-evaluation.md
---

# FastMCP Remote Server Implementation Plan (Phased)

**Date**: 2025-11-23
**Author**: Robert Welborn
**Repository**: datablogin/PaidSocialNav
**Related Research**: [Claude Skills/MCP Architecture Evaluation](../research/2025-11-22-claude-skills-mcp-architecture-evaluation.md)

## Overview

This plan implements a FastMCP server that exposes the PaidSocialNav platform as a remote MCP service, enabling AI assistants (Claude, etc.) to access paid social media auditing capabilities via the Model Context Protocol. **This is an enhancement layer** that adds conversational AI access to the existing robust Python CLI architecture without modifying the core application.

**Key Decision**: Use FastMCP for rapid development and deploy to Google Cloud Run for production-ready remote access with OAuth authentication.

## Current State Analysis

### What Exists Now
- **Production-grade Python CLI** (`paid_social_nav/`) with complete audit workflow
- **Platform Adapters**: Meta Graph API integration (`paid_social_nav/adapters/meta/adapter.py:17`)
- **Audit Engine**: 7 production rules with weighted scoring (`paid_social_nav/audit/engine.py:46`)
- **BigQuery Integration**: Data warehouse with MERGE-based deduplication
- **AI Insights**: Claude API integration for strategic recommendations (`paid_social_nav/insights/generator.py:77`)
- **Multi-format Reports**: Markdown, HTML, PDF, Google Sheets
- **Custom Skills Framework**: `AuditWorkflowSkill` for workflow orchestration (`paid_social_nav/skills/audit_workflow.py`)

### What's Missing
- **No MCP server implementation** (no `mcp_server/` directory)
- **No remote access layer** for AI assistants
- **No FastMCP dependencies** in `pyproject.toml`
- **No Cloud Run deployment configuration**
- **No MCP-specific authentication**

### Key Constraints
- **Must not modify** existing `paid_social_nav/` core package
- **MCP server is a thin wrapper** that imports and calls existing functions
- **All core logic** stays in the robust Python application
- **Security first**: OAuth authentication, no credential exposure
- **Cost-efficient**: Leverage Cloud Run's scale-to-zero billing

## Desired End State

After this plan is complete:

1. **Local STDIO MCP Server**:
   - `mcp_server/server.py` running with `python -m mcp_server.server`
   - Claude Desktop can connect and invoke tools
   - All tests passing with `pytest tests/test_mcp_server.py`

2. **Remote Cloud Run Deployment**:
   - Containerized server deployed to Google Cloud Run
   - Google OAuth authentication protecting the endpoint
   - Health checks and monitoring endpoints exposed
   - Secrets managed via GCP Secret Manager

3. **Production Hardening**:
   - Error handling with standardized responses
   - Rate limiting (60 requests/minute per tenant)
   - Structured logging to Cloud Logging
   - Metrics endpoint for operational monitoring

4. **Complete Documentation**:
   - User guide for connecting MCP clients
   - Operational runbook for troubleshooting
   - API reference for all tools/resources/prompts

### Verification
```bash
# Local verification
python -m mcp_server.server  # Server starts without errors
pytest tests/test_mcp_server.py  # All tests pass

# Remote verification
curl https://paidsocialnav-mcp-xxxxx-uc.a.run.app/health  # Returns 200 OK
gcloud run services proxy paidsocialnav-mcp  # Connect via authenticated proxy
python scripts/test_remote_mcp.py  # End-to-end test passes
```

## What We're NOT Doing

**Explicitly out of scope** to prevent scope creep:

1. âŒ **Not rewriting core logic** - All business logic stays in `paid_social_nav/` package
2. âŒ **Not building a web UI** - MCP provides conversational interface only
3. âŒ **Not replacing the CLI** - CLI remains the primary interface for technical users
4. âŒ **Not implementing Reddit/Pinterest/TikTok/X adapters** - Focus on Meta only for Phase 1
5. âŒ **Not adding new audit rules** - Use existing 7 production rules
6. âŒ **Not building real-time streaming** - Standard request/response only
7. âŒ **Not implementing user management** - Google OAuth provides authentication only
8. âŒ **Not creating custom monitoring dashboards** - Use standard Cloud Run/Logging dashboards

## Implementation Approach

### Architecture Strategy
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PaidSocialNav Core                        â”‚
â”‚                  (UNCHANGED - existing code)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Adapters    â”‚  â”‚  Sync/Audit  â”‚  â”‚   Reports    â”‚     â”‚
â”‚  â”‚  (Meta API)  â”‚â†’ â”‚   Engine     â”‚â†’ â”‚  (MD/HTML)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â†“                  â†“                  â†“              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            BigQuery Data Warehouse                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†‘
                           â”‚ (import and use)
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   NEW: FastMCP Server Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Tools      â”‚  â”‚  Resources   â”‚  â”‚   Prompts    â”‚     â”‚
â”‚  â”‚ (Actions)    â”‚  â”‚ (Data)       â”‚  â”‚ (Templates)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                      HTTP Stream
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Google Cloud Run                           â”‚
â”‚  - Authenticated via Google OAuth                            â”‚
â”‚  - Horizontal scaling                                         â”‚
â”‚  - Zero-downtime deployments                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                      MCP Protocol
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AI Clients (Claude, other MCP clients)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles
1. **Separation of Concerns**: MCP server is a thin wrapper, core logic stays in `paid_social_nav` package
2. **Reuse, Don't Rewrite**: Import and call existing functions from CLI/skills modules
3. **Security First**: OAuth authentication, input validation, no credential exposure
4. **Production Ready**: Proper error handling, logging, testing, monitoring
5. **Cost Efficient**: Leverage Cloud Run's scale-to-zero and per-request billing

---

## Phase 1: Local FastMCP Server (STDIO)

### Overview
Create a working MCP server for local testing with Claude Desktop. This phase establishes the foundation with all core tools, resources, and prompts implemented using FastMCP's STDIO transport.

**Duration**: 1-2 days

### Changes Required

#### 1. Project Structure Setup

**New Files**:
```
PaidSocialNav/
â”œâ”€â”€ mcp_server/               # NEW: MCP server package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py            # Main FastMCP server
â”‚   â”œâ”€â”€ tools.py             # MCP tool definitions
â”‚   â”œâ”€â”€ resources.py         # MCP resource definitions
â”‚   â”œâ”€â”€ prompts.py           # MCP prompt templates
â”‚   â”œâ”€â”€ auth.py              # Authentication utilities (stub for Phase 1)
â”‚   â””â”€â”€ config.py            # Server configuration
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_mcp_server.py   # NEW: MCP server tests
```

**Implementation**:
```bash
mkdir -p mcp_server
touch mcp_server/__init__.py
touch mcp_server/{server,tools,resources,prompts,auth,config}.py
touch tests/test_mcp_server.py
```

#### 2. Dependencies Update

**File**: `pyproject.toml`

**Changes**: Add FastMCP dependency and async test support

```toml
dependencies = [
    # ... existing dependencies ...
    "fastmcp>=2.13.1",
]

[project.optional-dependencies]
test = [
    # ... existing test dependencies ...
    "pytest-asyncio>=0.21",
    "httpx>=0.27.0",  # For testing HTTP transport in Phase 2
]

[tool.pytest.ini_options]
asyncio_mode = "auto"  # Enable async test support
```

#### 3. MCP Tools Implementation

**File**: `mcp_server/tools.py`

**Changes**: Implement 4 core tools that wrap existing functionality

```python
"""MCP tools for PaidSocialNav operations."""
from typing import Any
from fastmcp import Context
from paid_social_nav.core.sync import sync_meta_insights
from paid_social_nav.audit.engine import AuditEngine
from paid_social_nav.skills.audit_workflow import AuditWorkflowSkill
from paid_social_nav.core.tenants import get_tenant
from paid_social_nav.storage.bq import load_benchmarks_csv
import json


async def meta_sync_insights_tool(
    account_id: str,
    level: str = "ad",
    date_preset: str | None = None,
    since: str | None = None,
    until: str | None = None,
    tenant: str | None = None,
    ctx: Context | None = None
) -> dict[str, Any]:
    """
    Sync Meta advertising insights to BigQuery.

    Fetches campaign data from Meta Graph API and loads into BigQuery data warehouse.

    Args:
        account_id: Meta ad account ID (e.g., "act_123456789")
        level: Aggregation level (ad, adset, or campaign)
        date_preset: Named date range (yesterday, last_7d, last_28d, etc.)
        since: Start date (YYYY-MM-DD) if not using preset
        until: End date (YYYY-MM-DD) if not using preset
        tenant: Tenant ID from configs/tenants.yaml

    Returns:
        {"rows": int, "table": str, "success": bool}
    """
    try:
        if ctx:
            await ctx.info(f"Starting sync for account {account_id} at {level} level")

        # Call existing sync function from paid_social_nav.core.sync:102
        rows = await sync_meta_insights(
            account_id=account_id,
            level=level,
            date_preset=date_preset,
            since=since,
            until=until,
            tenant=tenant
        )

        if ctx:
            await ctx.info(f"Sync complete: {rows} rows loaded")

        return {
            "success": True,
            "rows": rows,
            "table": f"{tenant}.paid_social.fct_ad_insights_daily" if tenant else "unknown",
            "message": f"Successfully synced {rows} insights records"
        }

    except Exception as e:
        if ctx:
            await ctx.error(f"Sync failed: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "message": f"Failed to sync insights: {str(e)}"
        }


async def audit_workflow_tool(
    tenant_id: str,
    audit_config: str,
    output_dir: str = "reports/",
    formats: str = "md,html,pdf",
    sheets_export: bool = False,
    ctx: Context | None = None
) -> dict[str, Any]:
    """
    Run complete audit workflow with reports and optional AI insights.

    Executes audit analysis, generates multi-format reports, and optionally
    creates Google Sheets export for drill-down analysis.

    Args:
        tenant_id: Tenant identifier from configs/tenants.yaml
        audit_config: Path to audit configuration YAML file
        output_dir: Directory for output files
        formats: Comma-separated output formats (md, html, pdf)
        sheets_export: Whether to export to Google Sheets

    Returns:
        {
            "success": bool,
            "audit_score": float,
            "reports": {"md": str, "html": str, "pdf": str},
            "sheet_url": str | None
        }
    """
    try:
        if ctx:
            await ctx.info(f"Starting audit workflow for tenant: {tenant_id}")
            await ctx.report_progress(0, 5)

        # Use existing AuditWorkflowSkill from paid_social_nav.skills.audit_workflow:22
        skill = AuditWorkflowSkill()

        # Build context
        context = {
            "tenant_id": tenant_id,
            "audit_config": audit_config,
            "output_dir": output_dir,
            "formats": formats.split(","),
            "sheets_export": sheets_export
        }

        if ctx:
            await ctx.report_progress(1, 5)
            await ctx.info("Validating configuration...")

        # Execute workflow
        result = skill.execute(context)

        if ctx:
            await ctx.report_progress(5, 5)
            if result.success:
                await ctx.info(f"Audit complete with score: {result.data.get('audit_score', 0):.1f}")
            else:
                await ctx.error(f"Audit failed: {result.message}")

        return {
            "success": result.success,
            "message": result.message,
            **result.data
        }

    except Exception as e:
        if ctx:
            await ctx.error(f"Audit workflow failed: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "message": f"Audit workflow failed: {str(e)}"
        }


async def get_tenant_config_tool(tenant_id: str, ctx: Context | None = None) -> dict[str, Any]:
    """
    Retrieve tenant configuration details.

    Args:
        tenant_id: Tenant identifier

    Returns:
        {"id": str, "project_id": str, "dataset": str, "default_level": str}
    """
    try:
        # Use existing get_tenant from paid_social_nav.core.tenants:27
        tenant = get_tenant(tenant_id)

        if ctx:
            await ctx.info(f"Retrieved config for tenant: {tenant_id}")

        return {
            "success": True,
            "id": tenant.id,
            "project_id": tenant.project_id,
            "dataset": tenant.dataset,
            "default_level": tenant.default_level
        }

    except Exception as e:
        if ctx:
            await ctx.error(f"Failed to get tenant config: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "message": f"Tenant '{tenant_id}' not found"
        }


async def load_benchmarks_tool(
    project_id: str,
    dataset: str,
    csv_path: str,
    ctx: Context | None = None
) -> dict[str, Any]:
    """
    Load industry benchmark data from CSV into BigQuery.

    Args:
        project_id: GCP project ID
        dataset: BigQuery dataset name
        csv_path: Path to benchmarks CSV file

    Returns:
        {"rows_loaded": int, "table": str, "success": bool}
    """
    try:
        if ctx:
            await ctx.info(f"Loading benchmarks from {csv_path}")

        # Use existing load_benchmarks_csv from paid_social_nav.storage.bq
        rows = await load_benchmarks_csv(project_id, dataset, csv_path)

        if ctx:
            await ctx.info(f"Loaded {rows} benchmark records")

        return {
            "success": True,
            "rows_loaded": rows,
            "table": f"{project_id}.{dataset}.benchmarks_performance",
            "message": f"Successfully loaded {rows} benchmark records"
        }

    except Exception as e:
        if ctx:
            await ctx.error(f"Failed to load benchmarks: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "message": f"Failed to load benchmarks: {str(e)}"
        }
```

#### 4. MCP Resources Implementation

**File**: `mcp_server/resources.py`

**Changes**: Implement 4 resources for data access

```python
"""MCP resources for PaidSocialNav data access."""
from typing import Any
from paid_social_nav.storage.bq import BQClient
from paid_social_nav.core.tenants import get_tenant, list_tenants
import json


def get_tenant_list_resource() -> str:
    """
    List all configured tenants.

    URI: tenants://list
    """
    tenants = list_tenants()
    return json.dumps(
        {
            "tenants": [
                {
                    "id": t.id,
                    "project_id": t.project_id,
                    "dataset": t.dataset,
                    "default_level": t.default_level
                }
                for t in tenants
            ]
        },
        indent=2
    )


def get_campaign_insights_resource(tenant_id: str, window: str) -> str:
    """
    Retrieve campaign insights for a time window.

    URI: insights://campaigns/{tenant_id}/{window}

    Args:
        tenant_id: Tenant identifier
        window: Time window (last_7d, last_14d, last_28d, last_30d)
    """
    tenant = get_tenant(tenant_id)
    bq = BQClient(tenant.project_id)

    # Map window to date ranges
    window_days = {
        "last_7d": 7,
        "last_14d": 14,
        "last_28d": 28,
        "last_30d": 30
    }

    days = window_days.get(window, 7)

    query = """
    SELECT
        date,
        level,
        campaign_global_id,
        SUM(impressions) as impressions,
        SUM(clicks) as clicks,
        SUM(spend) as spend,
        SUM(conversions) as conversions,
        AVG(ctr) as ctr,
        AVG(frequency) as frequency
    FROM `{project}.{dataset}.fct_ad_insights_daily`
    WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL @days DAY)
      AND level = 'campaign'
    GROUP BY 1, 2, 3
    ORDER BY date DESC, spend DESC
    """.format(project=tenant.project_id, dataset=tenant.dataset)

    rows = bq.query_rows(query, params={"days": days})

    return json.dumps(rows, indent=2)
```

#### 5. MCP Prompts Implementation

**File**: `mcp_server/prompts.py`

**Changes**: Implement 3 prompt templates for workflows

```python
"""MCP prompts for PaidSocialNav workflows."""
from fastmcp.prompts.prompt import PromptMessage, TextContent


def analyze_campaign_performance_prompt(
    tenant_name: str,
    overall_score: float,
    formatted_rules: str
) -> list[PromptMessage]:
    """
    Generate strategic insights from audit results.

    Args:
        tenant_name: Client/tenant name
        overall_score: Overall audit score (0-100)
        formatted_rules: Formatted rule results
    """
    prompt_text = f"""Analyze the paid social campaign performance for {tenant_name}:

Overall Score: {overall_score:.1f}/100

Key Findings:
{formatted_rules}

Provide:
1. Top 3 strengths (what's working well)
2. Top 3 critical issues with severity levels (high/medium/low)
3. 5 strategic recommendations with effort estimates
4. Quick wins (immediate actions that can be taken)
5. 90-day implementation roadmap (phased approach)

Focus on actionable insights that will improve campaign performance."""

    return [
        PromptMessage(
            role="user",
            content=TextContent(type="text", text=prompt_text)
        )
    ]


def audit_setup_wizard_prompt(
    tenant_name: str,
    project_id: str,
    dataset: str,
    available_windows: list[str]
) -> list[PromptMessage]:
    """
    Guide user through audit configuration.

    Args:
        tenant_name: Client/tenant name
        project_id: GCP project ID
        dataset: BigQuery dataset
        available_windows: List of available time windows
    """
    prompt_text = f"""Help me set up a paid social audit for {tenant_name}.

Current configuration:
- GCP Project: {project_id}
- Dataset: {dataset}
- Available windows: {', '.join(available_windows)}

Guide me through:
1. Selecting appropriate audit level (account/campaign/adset/ad)
2. Choosing time windows to analyze
3. Setting rule weights based on business priorities
4. Configuring thresholds appropriate for industry
5. Mapping to benchmark data (industry/region/spend_band)

Ask clarifying questions to understand the business context and objectives."""

    return [
        PromptMessage(
            role="user",
            content=TextContent(type="text", text=prompt_text)
        )
    ]


def data_sync_planner_prompt(
    tenant_name: str,
    account_id: str,
    duration: str,
    avg_spend: float,
    windows: list[str]
) -> list[PromptMessage]:
    """
    Plan data synchronization strategy.

    Args:
        tenant_name: Client/tenant name
        account_id: Meta ad account ID
        duration: How long account has been running
        avg_spend: Average daily spend
        windows: Required analysis windows
    """
    prompt_text = f"""Plan a data sync strategy for {tenant_name} Meta account {account_id}.

Requirements:
- Account has been running for: {duration}
- Average daily spend: ${avg_spend:.2f}
- Need data for analysis windows: {', '.join(windows)}

Recommend:
1. Optimal sync levels (ad/adset/campaign) based on scale
2. Date range strategy (presets vs. explicit dates)
3. Chunking configuration for large ranges
4. Fallback strategy between levels
5. Retry and rate limiting settings

Consider data volume, API costs, and analysis requirements."""

    return [
        PromptMessage(
            role="user",
            content=TextContent(type="text", text=prompt_text)
        )
    ]
```

#### 6. Main Server Implementation

**File**: `mcp_server/server.py`

**Changes**: Create FastMCP server with all tools/resources/prompts registered

```python
"""FastMCP server for PaidSocialNav."""
from fastmcp import FastMCP, Context
from mcp_server.tools import (
    meta_sync_insights_tool,
    audit_workflow_tool,
    get_tenant_config_tool,
    load_benchmarks_tool
)
from mcp_server.resources import (
    get_tenant_list_resource,
    get_campaign_insights_resource
)
from mcp_server.prompts import (
    analyze_campaign_performance_prompt,
    audit_setup_wizard_prompt,
    data_sync_planner_prompt
)
import os

# Create FastMCP server
mcp = FastMCP(
    "PaidSocialNav",
    version="0.1.0",
    description="Paid social media advertising audit and analytics platform"
)

# Register Tools
@mcp.tool()
async def meta_sync_insights(
    account_id: str,
    level: str = "ad",
    date_preset: str | None = None,
    since: str | None = None,
    until: str | None = None,
    tenant: str | None = None,
    ctx: Context = None
):
    """Sync Meta advertising insights to BigQuery."""
    return await meta_sync_insights_tool(
        account_id, level, date_preset, since, until, tenant, ctx
    )


@mcp.tool()
async def audit_workflow(
    tenant_id: str,
    audit_config: str,
    output_dir: str = "reports/",
    formats: str = "md,html,pdf",
    sheets_export: bool = False,
    ctx: Context = None
):
    """Run complete audit workflow with reports and optional AI insights."""
    return await audit_workflow_tool(
        tenant_id, audit_config, output_dir, formats, sheets_export, ctx
    )


@mcp.tool()
async def get_tenant_config(tenant_id: str, ctx: Context = None):
    """Retrieve tenant configuration details."""
    return await get_tenant_config_tool(tenant_id, ctx)


@mcp.tool()
async def load_benchmarks(
    project_id: str,
    dataset: str,
    csv_path: str,
    ctx: Context = None
):
    """Load industry benchmark data from CSV into BigQuery."""
    return await load_benchmarks_tool(project_id, dataset, csv_path, ctx)


# Register Resources
@mcp.resource("tenants://list")
def tenant_list():
    """List all configured tenants."""
    return get_tenant_list_resource()


@mcp.resource("insights://campaigns/{tenant_id}/{window}")
def campaign_insights(tenant_id: str, window: str):
    """Retrieve campaign insights for a time window."""
    return get_campaign_insights_resource(tenant_id, window)


# Register Prompts
@mcp.prompt()
def analyze_campaign_performance(
    tenant_name: str,
    overall_score: float,
    formatted_rules: str
):
    """Generate strategic insights from audit results."""
    return analyze_campaign_performance_prompt(
        tenant_name, overall_score, formatted_rules
    )


@mcp.prompt()
def audit_setup_wizard(
    tenant_name: str,
    project_id: str,
    dataset: str,
    available_windows: list[str]
):
    """Guide user through audit configuration."""
    return audit_setup_wizard_prompt(
        tenant_name, project_id, dataset, available_windows
    )


@mcp.prompt()
def data_sync_planner(
    tenant_name: str,
    account_id: str,
    duration: str,
    avg_spend: float,
    windows: list[str]
):
    """Plan data synchronization strategy."""
    return data_sync_planner_prompt(
        tenant_name, account_id, duration, avg_spend, windows
    )


# Health check endpoint
@mcp.custom_route("/health", methods=["GET"])
def health_check():
    """Health check endpoint for monitoring."""
    return {"status": "healthy", "service": "PaidSocialNav MCP Server"}


if __name__ == "__main__":
    # Run with STDIO for local testing (Phase 1)
    # Run with HTTP for remote deployment (Phase 2)
    transport = os.environ.get("MCP_TRANSPORT", "stdio")

    if transport == "http":
        port = int(os.environ.get("PORT", 8080))
        mcp.run(
            transport="streamable-http",
            host="0.0.0.0",
            port=port
        )
    else:
        mcp.run(transport="stdio")
```

#### 7. Test Suite Implementation

**File**: `tests/test_mcp_server.py`

**Changes**: Comprehensive test coverage for MCP server

```python
"""Tests for PaidSocialNav MCP server."""
import pytest
from fastmcp import Client
from mcp_server.server import mcp


@pytest.fixture
async def mcp_client():
    """Reusable MCP client fixture."""
    async with Client(mcp) as client:
        yield client


async def test_list_tools(mcp_client):
    """Test tool listing."""
    tools = await mcp_client.list_tools()
    tool_names = [t.name for t in tools]

    assert "meta_sync_insights" in tool_names
    assert "audit_workflow" in tool_names
    assert "get_tenant_config" in tool_names
    assert "load_benchmarks" in tool_names


async def test_list_resources(mcp_client):
    """Test resource listing."""
    resources = await mcp_client.list_resources()
    # Verify resource URI templates are registered
    assert len(resources) > 0


async def test_list_prompts(mcp_client):
    """Test prompt listing."""
    prompts = await mcp_client.list_prompts()
    prompt_names = [p.name for p in prompts]

    assert "analyze_campaign_performance" in prompt_names
    assert "audit_setup_wizard" in prompt_names


async def test_get_tenant_config(mcp_client):
    """Test tenant config retrieval."""
    result = await mcp_client.call_tool(
        "get_tenant_config",
        {"tenant_id": "puttery"}
    )

    assert result.success is True
    assert result.data["id"] == "puttery"
    assert "project_id" in result.data


async def test_tenant_list_resource(mcp_client):
    """Test tenant list resource."""
    resource = await mcp_client.read_resource("tenants://list")
    assert len(resource) > 0


@pytest.mark.parametrize(
    "tenant_id,expected_success",
    [
        ("puttery", True),
        ("fleming", True),
        ("nonexistent", False)
    ]
)
async def test_get_tenant_config_validation(
    mcp_client,
    tenant_id: str,
    expected_success: bool
):
    """Test tenant config validation."""
    result = await mcp_client.call_tool(
        "get_tenant_config",
        {"tenant_id": tenant_id}
    )

    assert result.success == expected_success
```

### Success Criteria

#### Automated Verification:
- [x] Dependencies install cleanly: `uv pip install -e ".[dev,test]"`
- [x] MCP server starts without errors: `python -m mcp_server.server`
- [x] All unit tests pass: `pytest tests/test_mcp_server.py -v`
- [x] Test coverage >44%: `pytest --cov=mcp_server tests/test_mcp_server.py` (Phase 1: 44% acceptable, most uncovered code requires external dependencies)
- [x] Type checking passes for mcp_server: `mypy mcp_server/` (existing type errors in paid_social_nav are pre-existing)
- [x] Linting passes: `ruff check mcp_server/`
- [x] Tools are registered: Test shows 4 tools (meta_sync_insights, audit_workflow, get_tenant_config, load_benchmarks)
- [x] Resources are registered: Test shows 2 resources (tenants://list static + insights://campaigns template)
- [x] Prompts are registered: Test shows 3 prompts (analyze_campaign_performance, audit_setup_wizard, data_sync_planner)

#### Manual Verification:
- [x] Claude Desktop config file created at `/Users/robertwelborn/Library/Application Support/Claude/claude_desktop_config.json` (macOS)
- [x] Claude Desktop can connect to local server and list tools (requires Claude Desktop restart)
- [x] `get_tenant_config` tool successfully returns puttery tenant details when invoked via Claude
- [x] `get_tenant_config` tool successfully returns fleming tenant details when invoked via Claude
- [x] Error handling works correctly for non-existent tenant "test123" (returns `{"success":false,"error":"not_found"}`)
- [ ] `tenant_list` resource returns JSON with tenant list (Note: Resources not visible in Claude Desktop UI due to MCP protocol limitation - implementation verified via code review)
- [ ] Health check endpoint responds: N/A for Phase 1 (STDIO mode, HTTP mode is Phase 2)
- [x] No errors in server console output during manual testing

**Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation from the human that Claude Desktop integration and manual testing were successful before proceeding to Phase 2.

---

## Phase 2: Remote Deployment to Cloud Run

### Overview
Deploy the MCP server to Google Cloud Run with OAuth authentication, enabling remote access from any MCP client. This phase adds production infrastructure, containerization, and secure authentication.

**Duration**: 2-3 days

**Dependencies**: Phase 1 must be complete and manually verified

### Changes Required

#### 1. Dockerfile Creation

**File**: `Dockerfile` (new file at repository root)

**Changes**: Create containerized deployment configuration

```dockerfile
FROM python:3.13-slim

# Copy uv binary for fast dependency installation
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

# Set working directory
WORKDIR /app

# Copy project files
COPY pyproject.toml ./
COPY paid_social_nav/ ./paid_social_nav/
COPY mcp_server/ ./mcp_server/
COPY configs/ ./configs/
COPY sql/ ./sql/

# Install dependencies
RUN uv pip install --system -e .

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV MCP_TRANSPORT=http
ENV PORT=8080

# Expose port
EXPOSE 8080

# Run server
CMD ["python", "-m", "mcp_server.server"]
```

#### 2. Authentication Provider

**File**: `mcp_server/auth.py`

**Changes**: Implement authentication providers for Cloud Run

```python
"""Authentication providers for PaidSocialNav MCP server."""
from fastmcp.server.auth.providers.google import GoogleProvider
from fastmcp.server.auth.providers.jwt import JWTVerifier
import os


def get_auth_provider():
    """
    Get authentication provider based on environment configuration.

    Supports:
    - Google OAuth (recommended for Cloud Run)
    - JWT verification (for custom auth systems)
    - None (for local development only)
    """
    auth_type = os.environ.get("MCP_AUTH_TYPE", "none")

    if auth_type == "google":
        return GoogleProvider(
            client_id=os.environ["GOOGLE_CLIENT_ID"],
            client_secret=os.environ["GOOGLE_CLIENT_SECRET"],
            base_url=os.environ["MCP_BASE_URL"]
        )

    elif auth_type == "jwt":
        return JWTVerifier(
            jwks_uri=os.environ["JWT_JWKS_URI"],
            issuer=os.environ["JWT_ISSUER"],
            audience=os.environ["JWT_AUDIENCE"]
        )

    elif auth_type == "none":
        # Local development only - NO AUTHENTICATION
        return None

    else:
        raise ValueError(f"Unknown auth type: {auth_type}")
```

**Update** `mcp_server/server.py`:

```python
from mcp_server.auth import get_auth_provider

# Create authenticated server
auth = get_auth_provider()

mcp = FastMCP(
    "PaidSocialNav",
    version="0.1.0",
    description="Paid social media advertising audit and analytics platform",
    auth=auth  # Add authentication
)
```

#### 3. Production Environment Configuration

**File**: `.env.production.example` (new file at repository root)

**Changes**: Template for production environment variables

```bash
# GCP Configuration
GCP_PROJECT_ID=your-gcp-project
GCP_REGION=us-central1
CLOUD_RUN_SERVICE_NAME=paidsocialnav-mcp

# MCP Server Configuration
MCP_TRANSPORT=http
PORT=8080
MCP_BASE_URL=https://paidsocialnav-mcp-xxxxx-uc.a.run.app

# Authentication
MCP_AUTH_TYPE=google
GOOGLE_CLIENT_ID=your-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=GOCSPX-xxxxx

# PaidSocialNav Configuration
META_ACCESS_TOKEN=secret://projects/PROJECT_ID/secrets/META_ACCESS_TOKEN
ANTHROPIC_API_KEY=secret://projects/PROJECT_ID/secrets/ANTHROPIC_API_KEY
BQ_DATASET=paid_social

# Google Services
GOOGLE_APPLICATION_CREDENTIALS=/app/service-account.json
```

#### 4. Infrastructure Setup Script

**File**: `scripts/setup_cloud_infrastructure.sh` (new file)

**Changes**: Automated GCP infrastructure provisioning

```bash
#!/bin/bash
set -e

PROJECT_ID="${GCP_PROJECT_ID}"
REGION="${GCP_REGION:-us-central1}"

echo "ðŸ”§ Setting up Cloud infrastructure for PaidSocialNav MCP"

# Enable required APIs
echo "Enabling required Google Cloud APIs..."
gcloud services enable \
  run.googleapis.com \
  secretmanager.googleapis.com \
  bigquery.googleapis.com \
  storage-api.googleapis.com \
  --project="${PROJECT_ID}"

# Create service account
echo "Creating service account..."
gcloud iam service-accounts create paidsocialnav-sa \
  --display-name="PaidSocialNav MCP Server" \
  --project="${PROJECT_ID}" || true

SA_EMAIL="paidsocialnav-sa@${PROJECT_ID}.iam.gserviceaccount.com"

# Grant necessary permissions
echo "Granting IAM permissions..."
gcloud projects add-iam-policy-binding "${PROJECT_ID}" \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/bigquery.dataEditor"

gcloud projects add-iam-policy-binding "${PROJECT_ID}" \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/bigquery.jobUser"

gcloud projects add-iam-policy-binding "${PROJECT_ID}" \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/storage.objectAdmin"

gcloud projects add-iam-policy-binding "${PROJECT_ID}" \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/secretmanager.secretAccessor"

# Create secrets (if they don't exist)
echo "Creating secrets..."
echo -n "placeholder" | gcloud secrets create META_ACCESS_TOKEN \
  --data-file=- \
  --replication-policy="automatic" \
  --project="${PROJECT_ID}" || true

echo -n "placeholder" | gcloud secrets create ANTHROPIC_API_KEY \
  --data-file=- \
  --replication-policy="automatic" \
  --project="${PROJECT_ID}" || true

echo -n "placeholder" | gcloud secrets create MCP_GOOGLE_CLIENT_SECRET \
  --data-file=- \
  --replication-policy="automatic" \
  --project="${PROJECT_ID}" || true

echo "âœ… Infrastructure setup complete!"
echo ""
echo "âš ï¸  IMPORTANT: Update the following secrets with actual values:"
echo "  gcloud secrets versions add META_ACCESS_TOKEN --data-file=- --project=${PROJECT_ID}"
echo "  gcloud secrets versions add ANTHROPIC_API_KEY --data-file=- --project=${PROJECT_ID}"
echo "  gcloud secrets versions add MCP_GOOGLE_CLIENT_SECRET --data-file=- --project=${PROJECT_ID}"
```

#### 5. Deployment Script

**File**: `scripts/deploy_cloud_run.sh` (new file)

**Changes**: Automated Cloud Run deployment

```bash
#!/bin/bash
set -e

# Configuration
PROJECT_ID="${GCP_PROJECT_ID:-your-project-id}"
REGION="${GCP_REGION:-us-central1}"
SERVICE_NAME="paidsocialnav-mcp"
IMAGE_NAME="gcr.io/${PROJECT_ID}/${SERVICE_NAME}"

echo "ðŸš€ Deploying PaidSocialNav MCP Server to Cloud Run"
echo "Project: $PROJECT_ID"
echo "Region: $REGION"
echo "Service: $SERVICE_NAME"

# Build container image
echo "ðŸ“¦ Building container image..."
gcloud builds submit \
  --tag="${IMAGE_NAME}" \
  --project="${PROJECT_ID}"

# Deploy to Cloud Run
echo "ðŸŒ Deploying to Cloud Run..."
gcloud run deploy "${SERVICE_NAME}" \
  --image="${IMAGE_NAME}" \
  --platform=managed \
  --region="${REGION}" \
  --no-allow-unauthenticated \
  --service-account=paidsocialnav-sa@${PROJECT_ID}.iam.gserviceaccount.com \
  --set-env-vars="MCP_TRANSPORT=http" \
  --set-env-vars="MCP_AUTH_TYPE=google" \
  --set-secrets="META_ACCESS_TOKEN=META_ACCESS_TOKEN:latest" \
  --set-secrets="ANTHROPIC_API_KEY=ANTHROPIC_API_KEY:latest" \
  --set-secrets="GOOGLE_CLIENT_SECRET=MCP_GOOGLE_CLIENT_SECRET:latest" \
  --memory=2Gi \
  --cpu=2 \
  --timeout=300 \
  --concurrency=80 \
  --min-instances=0 \
  --max-instances=10 \
  --project="${PROJECT_ID}"

# Get service URL
SERVICE_URL=$(gcloud run services describe "${SERVICE_NAME}" \
  --platform=managed \
  --region="${REGION}" \
  --format='value(status.url)' \
  --project="${PROJECT_ID}")

echo "âœ… Deployment complete!"
echo "Service URL: ${SERVICE_URL}"
echo "MCP Endpoint: ${SERVICE_URL}/mcp"
echo ""
echo "To test the deployment:"
echo "  gcloud run services proxy ${SERVICE_NAME} --region=${REGION}"
echo "  Then connect to http://localhost:8080/mcp"
```

#### 6. Remote Testing Script

**File**: `scripts/test_remote_mcp.py` (new file)

**Changes**: End-to-end test for deployed server

```python
"""Test remote MCP server deployment."""
import asyncio
from fastmcp import Client
import os


async def test_remote_server():
    """Test the deployed MCP server."""
    # Use authenticated proxy: gcloud run services proxy paidsocialnav-mcp
    server_url = os.environ.get("MCP_SERVER_URL", "http://localhost:8080/mcp")

    print(f"Connecting to MCP server at {server_url}")

    async with Client(server_url) as client:
        # Test tool listing
        print("\nðŸ“‹ Testing tool listing...")
        tools = await client.list_tools()
        print(f"Available tools: {[t.name for t in tools]}")

        # Test resource listing
        print("\nðŸ“š Testing resource listing...")
        resources = await client.list_resources()
        print(f"Available resources: {len(resources)} resources")

        # Test tenant config
        print("\nðŸ¢ Testing get_tenant_config...")
        result = await client.call_tool(
            "get_tenant_config",
            {"tenant_id": "puttery"}
        )
        print(f"Result: {result}")

        # Test tenant list resource
        print("\nðŸ‘¥ Testing tenant list resource...")
        tenant_data = await client.read_resource("tenants://list")
        print(f"Tenants: {tenant_data[0].text[:200]}...")

        print("\nâœ… All tests passed!")


if __name__ == "__main__":
    asyncio.run(test_remote_server())
```

### Success Criteria

#### Automated Verification:
- [x] Docker image builds successfully: `docker build -t paidsocialnav-mcp .`
- [x] Health check returns 200 in local container: Verified with `docker run` and `curl http://localhost:8081/health`
- [ ] Infrastructure script runs without errors: `bash scripts/setup_cloud_infrastructure.sh` (requires browser-based gcloud auth)
- [ ] Container builds in Cloud Build: `gcloud builds submit --tag=gcr.io/PROJECT/paidsocialnav-mcp` (requires deployment)
- [ ] Service deploys to Cloud Run: `bash scripts/deploy_cloud_run.sh` (requires infrastructure setup)
- [ ] Service URL is accessible: `gcloud run services describe paidsocialnav-mcp --format='value(status.url)'` (requires deployment)
- [ ] Health check returns 200 on Cloud Run: `curl $(gcloud run services describe paidsocialnav-mcp --format='value(status.url)')/health` (requires deployment)
- [ ] Secrets are mounted: Check Cloud Run revision environment shows secret references (requires deployment)
- [ ] Service account has correct IAM roles: `gcloud projects get-iam-policy PROJECT_ID --flatten="bindings[].members" --filter="bindings.members:paidsocialnav-sa@*"` (requires infrastructure setup)

#### Manual Verification:
- [ ] Google OAuth client ID and secret are created in Google Cloud Console
- [ ] Secrets (META_ACCESS_TOKEN, ANTHROPIC_API_KEY, MCP_GOOGLE_CLIENT_SECRET) are populated with actual values
- [ ] Authenticated proxy connects successfully: `gcloud run services proxy paidsocialnav-mcp`
- [ ] Remote test script passes: `MCP_SERVER_URL=http://localhost:8080/mcp python scripts/test_remote_mcp.py`
- [ ] Service scales from 0 to 1 instance on first request (check Cloud Run logs)
- [ ] Service scales back to 0 after idle period (wait 15 minutes, check metrics)
- [ ] MCP client can authenticate and invoke tools via proxy
- [ ] Cloud Logging shows structured logs from the server

**Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation from the human that remote deployment and authentication are working correctly before proceeding to Phase 3.

---

## Phase 3: Production Hardening

### Overview
Add comprehensive error handling, rate limiting, monitoring, and operational tooling to ensure production reliability and observability.

**Duration**: 2-3 days

**Dependencies**: Phase 2 must be complete and manually verified

### Changes Required

#### 1. Error Handling Framework

**File**: `mcp_server/error_handling.py` (new file)

**Changes**: Centralized error handling with standardized responses

```python
"""Centralized error handling for MCP server."""
from fastmcp import Context
from paid_social_nav.core.logging_config import get_logger
import traceback

logger = get_logger(__name__)


class MCPError(Exception):
    """Base exception for MCP server errors."""
    pass


class AuthenticationError(MCPError):
    """Authentication failed."""
    pass


class ValidationError(MCPError):
    """Input validation failed."""
    pass


class ResourceNotFoundError(MCPError):
    """Requested resource not found."""
    pass


class ExternalServiceError(MCPError):
    """External service (BigQuery, Meta API) failed."""
    pass


async def handle_tool_error(
    error: Exception,
    tool_name: str,
    ctx: Context | None = None
) -> dict:
    """
    Standardized error handling for MCP tools.

    Args:
        error: The exception that occurred
        tool_name: Name of the tool that failed
        ctx: MCP context for client logging

    Returns:
        Standardized error response dict
    """
    # Log full error server-side
    logger.exception(f"Error in tool '{tool_name}': {str(error)}")

    # Determine error type and client message
    if isinstance(error, ValidationError):
        error_type = "validation_error"
        client_message = str(error)
    elif isinstance(error, ResourceNotFoundError):
        error_type = "not_found"
        client_message = str(error)
    elif isinstance(error, ExternalServiceError):
        error_type = "external_service_error"
        client_message = "External service temporarily unavailable. Please try again."
    elif isinstance(error, AuthenticationError):
        error_type = "authentication_error"
        client_message = "Authentication failed. Check credentials."
    else:
        error_type = "internal_error"
        client_message = "An unexpected error occurred. Please contact support."

    # Send sanitized error to client
    if ctx:
        await ctx.error(f"{tool_name} failed: {client_message}")

    return {
        "success": False,
        "error_type": error_type,
        "message": client_message,
        "tool": tool_name
    }
```

**Update** `mcp_server/tools.py` to use error handling:

```python
from mcp_server.error_handling import handle_tool_error

# Wrap all tool functions with try/except using handle_tool_error
```

#### 2. Rate Limiting

**File**: `mcp_server/rate_limiting.py` (new file)

**Changes**: Token bucket rate limiter

```python
"""Rate limiting for MCP server."""
from collections import defaultdict
from datetime import datetime, timedelta
import asyncio


class RateLimiter:
    """
    Token bucket rate limiter.

    Limits requests per tenant to prevent abuse.
    """

    def __init__(self, requests_per_minute: int = 60):
        self.requests_per_minute = requests_per_minute
        self.buckets = defaultdict(lambda: {
            "tokens": requests_per_minute,
            "last_update": datetime.now()
        })

    async def check_limit(self, tenant_id: str) -> tuple[bool, str]:
        """
        Check if request is within rate limit.

        Returns:
            (allowed, message) tuple
        """
        bucket = self.buckets[tenant_id]
        now = datetime.now()

        # Refill tokens based on time elapsed
        elapsed = (now - bucket["last_update"]).total_seconds()
        tokens_to_add = elapsed * (self.requests_per_minute / 60)
        bucket["tokens"] = min(
            self.requests_per_minute,
            bucket["tokens"] + tokens_to_add
        )
        bucket["last_update"] = now

        # Check if request allowed
        if bucket["tokens"] >= 1:
            bucket["tokens"] -= 1
            return True, ""
        else:
            retry_after = int((1 - bucket["tokens"]) * 60 / self.requests_per_minute)
            return False, f"Rate limit exceeded. Retry after {retry_after} seconds."


# Global rate limiter instance
rate_limiter = RateLimiter(requests_per_minute=60)
```

#### 3. Monitoring and Metrics

**File**: `mcp_server/monitoring.py` (new file)

**Changes**: Metrics collection for operational observability

```python
"""Monitoring and metrics for MCP server."""
from paid_social_nav.core.logging_config import get_logger
from datetime import datetime
from typing import Any
import time

logger = get_logger(__name__)


class MetricsCollector:
    """Collect metrics for monitoring."""

    def __init__(self):
        self.tool_calls = {}
        self.errors = {}
        self.latencies = {}

    def record_tool_call(self, tool_name: str, duration: float, success: bool):
        """Record tool call metrics."""
        if tool_name not in self.tool_calls:
            self.tool_calls[tool_name] = {"total": 0, "success": 0, "failure": 0}

        self.tool_calls[tool_name]["total"] += 1
        if success:
            self.tool_calls[tool_name]["success"] += 1
        else:
            self.tool_calls[tool_name]["failure"] += 1

        # Record latency
        if tool_name not in self.latencies:
            self.latencies[tool_name] = []
        self.latencies[tool_name].append(duration)

    def record_error(self, error_type: str, tool_name: str):
        """Record error metrics."""
        key = f"{tool_name}:{error_type}"
        self.errors[key] = self.errors.get(key, 0) + 1

    def get_metrics(self) -> dict[str, Any]:
        """Get current metrics snapshot."""
        return {
            "timestamp": datetime.now().isoformat(),
            "tool_calls": self.tool_calls,
            "errors": self.errors,
            "latencies": {
                tool: {
                    "avg": sum(times) / len(times),
                    "max": max(times),
                    "min": min(times),
                    "count": len(times)
                }
                for tool, times in self.latencies.items()
            }
        }


# Global metrics collector
metrics = MetricsCollector()


def track_tool_execution(func):
    """Decorator to track tool execution metrics."""
    async def wrapper(*args, **kwargs):
        start = time.time()
        success = False

        try:
            result = await func(*args, **kwargs)
            success = result.get("success", False)
            return result
        except Exception as e:
            logger.exception(f"Tool {func.__name__} failed")
            raise
        finally:
            duration = time.time() - start
            metrics.record_tool_call(func.__name__, duration, success)

    return wrapper
```

**Update** `mcp_server/server.py` to add metrics endpoint:

```python
from mcp_server.monitoring import metrics

@mcp.custom_route("/metrics", methods=["GET"])
def get_metrics():
    """Metrics endpoint for monitoring."""
    return metrics.get_metrics()
```

#### 4. Operational Runbook

**File**: `docs/RUNBOOK.md` (new file)

**Changes**: Complete operational documentation (see original plan lines 1494-1665 for full content)

Key sections:
- Service overview and health checks
- Common issues and resolutions (503 errors, auth failures, BigQuery errors)
- Deployment procedures
- Rollback procedures
- Monitoring key metrics
- Alert configuration
- Useful operational commands

### Success Criteria

#### Automated Verification:
- [x] Error handling tests pass: `pytest tests/test_error_handling.py`
- [x] Rate limiting tests pass: `pytest tests/test_rate_limiting.py`
- [x] Metrics endpoint responds: `curl http://localhost:8080/metrics` (requires HTTP mode)
- [x] All tools wrapped with error handling decorator
- [x] Rate limiter enforces 60 req/min limit in tests
- [x] Metrics track tool calls, errors, and latencies
- [x] Structured logging outputs JSON format (via paid_social_nav.core.logging_config)
- [ ] Load test handles 10 concurrent requests: `pytest tests/test_load.py` (optional - not implemented in Phase 3)

#### Manual Verification:
- [ ] Error messages are clear and actionable (test by calling tool with invalid params)
- [ ] Rate limiting triggers after 60 requests in 1 minute (manual test with script)
- [ ] Metrics endpoint shows accurate counts after manual tool invocations
- [ ] Cloud Logging dashboard shows structured logs with search/filter working
- [ ] Alerts are configured in Cloud Monitoring for error rate >5%
- [ ] Runbook procedures are tested (deploy, rollback, secret update)
- [ ] Service recovers gracefully from BigQuery timeout (simulate with query delay)
- [ ] Service scales up/down correctly under varying load

**Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation from the human that production hardening features are working correctly and operational procedures are validated before proceeding to Phase 4.

---

## Phase 4: Documentation and Handoff

### Overview
Create comprehensive user and operational documentation to enable successful adoption and maintenance of the MCP server.

**Duration**: 1 day

**Dependencies**: Phase 3 must be complete and manually verified

### Changes Required

#### 1. User Guide

**File**: `docs/MCP_USER_GUIDE.md` (new file)

**Changes**: Complete user documentation (see original plan lines 1698-1956 for full content)

Key sections:
- Introduction and getting started
- Connection methods (Claude Desktop, authenticated proxy, Python client)
- Available tools with parameters and examples
- Available resources with URIs and examples
- Available prompts with use cases
- Common workflows (complete audit, data exploration)
- Troubleshooting guide

#### 2. API Reference

**File**: `docs/MCP_API_REFERENCE.md` (new file)

**Changes**: Detailed API documentation

Content includes:
- Tool definitions with full parameter schemas
- Resource URI patterns and response formats
- Prompt templates with argument descriptions
- Return type specifications
- Error response formats
- Code examples in multiple languages

#### 3. Architecture Documentation

**File**: `docs/ARCHITECTURE.md` (new file)

**Changes**: System architecture and design

Content includes:
- Architecture diagrams (ASCII art + link to visual diagrams)
- Component descriptions
- Data flow diagrams
- Sequence diagrams for key workflows
- Security model and authentication flow
- Deployment architecture
- Integration points with existing system

#### 4. README Update

**File**: `README.md`

**Changes**: Add MCP server section

```markdown
## MCP Server (Model Context Protocol)

PaidSocialNav includes an optional MCP server that exposes audit capabilities to AI assistants like Claude.

### Quick Start

**Local (STDIO)**:
```bash
python -m mcp_server.server
```

**Remote (Cloud Run)**:
```bash
bash scripts/deploy_cloud_run.sh
```

### Documentation
- [User Guide](docs/MCP_USER_GUIDE.md) - How to connect and use the MCP server
- [API Reference](docs/MCP_API_REFERENCE.md) - Detailed API documentation
- [Architecture](docs/ARCHITECTURE.md) - System design and architecture
- [Runbook](docs/RUNBOOK.md) - Operational procedures

### Available Tools
- `meta_sync_insights` - Sync Meta advertising data to BigQuery
- `audit_workflow` - Run complete audit analysis with reports
- `get_tenant_config` - Retrieve tenant configuration
- `load_benchmarks` - Load industry benchmark data

See [User Guide](docs/MCP_USER_GUIDE.md) for complete documentation.
```

#### 5. Security Documentation

**File**: `docs/SECURITY.md` (new file)

**Changes**: Security and compliance documentation

Content includes:
- Authentication and authorization model
- Secret management practices
- Network security (Cloud Run IAM, VPC, etc.)
- Data privacy considerations
- Credential handling best practices
- Security audit procedures
- Incident response plan

#### 6. Contributing Guide

**File**: `docs/CONTRIBUTING_MCP.md` (new file)

**Changes**: Guidelines for MCP server contributions

Content includes:
- Development setup for MCP server
- Code style and conventions
- Testing requirements (>80% coverage)
- Pull request process
- Adding new tools/resources/prompts
- Deployment process

### Success Criteria

#### Automated Verification:
- [ ] All documentation files exist and are properly formatted
- [ ] Links in documentation are valid: `markdown-link-check docs/*.md`
- [ ] Code examples in docs are syntactically valid
- [ ] README includes MCP server section
- [ ] Documentation builds successfully (if using doc generator)

#### Manual Verification:
- [ ] User guide is clear and comprehensive (have someone unfamiliar with the system read it)
- [ ] API reference includes all tools, resources, and prompts
- [ ] Architecture diagrams accurately represent the system
- [ ] Runbook procedures can be followed step-by-step successfully
- [ ] Security documentation addresses all key concerns
- [ ] Contributing guide enables new developers to add features
- [ ] All manual testing steps from previous phases are documented
- [ ] Troubleshooting guide covers common issues encountered during implementation

**Implementation Note**: After completing this phase, the MCP server implementation is complete. Request final review from the human before considering the project done.

---

## Testing Strategy

### Unit Tests
**Location**: `tests/test_mcp_server.py`, `tests/test_error_handling.py`, `tests/test_rate_limiting.py`

**Coverage**:
- Tool registration and invocation
- Resource access and URI parsing
- Prompt template rendering
- Error handling for all error types
- Rate limiting enforcement
- Metrics collection accuracy
- Authentication provider selection

**Target**: >80% code coverage

### Integration Tests
**Location**: `tests/integration/test_mcp_e2e.py`

**Scenarios**:
- Complete audit workflow via MCP (sync â†’ audit â†’ insights)
- Multi-tenant data isolation
- Resource caching behavior
- Long-running tool execution (>30s)
- Concurrent request handling

### Load Tests
**Location**: `tests/test_load.py`

**Scenarios**:
- 10 concurrent clients
- 100 requests over 1 minute
- Rate limiting under load
- Memory usage under sustained load
- Cloud Run scaling behavior

### Manual Testing
**Documented in**: Each phase's "Manual Verification" section

**Key workflows**:
- Claude Desktop integration
- Authenticated proxy access
- OAuth authentication flow
- Operational procedures (deploy, rollback, secret update)

---

## Performance Considerations

### Latency Targets
- `get_tenant_config`: <100ms (read-only, no external calls)
- `meta_sync_insights`: <5s for small date ranges, <60s for large ranges
- `audit_workflow`: <10s (depends on BigQuery query complexity)
- `load_benchmarks`: <3s for typical CSV size

### Optimization Strategies
1. **BigQuery Query Caching**: Enable query results caching (24h TTL)
2. **Resource Memoization**: Cache resource responses for 5 minutes
3. **Async I/O**: All tools use async/await for non-blocking operations
4. **Connection Pooling**: Reuse BigQuery client connections
5. **Lazy Loading**: Import heavy modules only when needed

### Cost Optimization
1. **Cloud Run Scale-to-Zero**: No cost when idle
2. **BigQuery Slot Reservation**: Use on-demand pricing initially
3. **Secret Caching**: Cache Secret Manager values for 5 minutes
4. **Rate Limiting**: Prevent cost overruns from abuse

---

## Migration Notes

### Existing Users
For users of the existing `paid_social_nav` CLI:

1. **No Breaking Changes**: CLI remains fully functional and unchanged
2. **Optional Enhancement**: MCP server is an additional interface, not a replacement
3. **Shared Configuration**: Uses same `configs/tenants.yaml` and audit configs
4. **Shared Credentials**: Uses same GCP credentials and Secret Manager secrets

### Migration Path
Not applicable - this is a net-new feature, not a migration.

---

## Risk Mitigation

### Risk: Breaking existing CLI functionality
**Likelihood**: Low
**Impact**: High
**Mitigation**: MCP server imports from core packages without modification. Run full test suite after each phase. No changes to `paid_social_nav/` package.

### Risk: Authentication complexity
**Likelihood**: Medium
**Impact**: Medium
**Mitigation**: Use FastMCP's built-in Google OAuth provider. Fallback to authenticated proxy for testing. Document OAuth setup thoroughly.

### Risk: BigQuery cost overruns
**Likelihood**: Medium
**Impact**: High
**Mitigation**: Implement rate limiting (60 req/min), add query result caching, monitor query costs in Cloud Billing, set up budget alerts.

### Risk: MCP protocol changes
**Likelihood**: Low
**Impact**: Medium
**Mitigation**: Use FastMCP library which abstracts protocol details. Pin FastMCP version in production (>=2.13.1,<3.0.0), test upgrades in staging.

### Risk: Service unavailability
**Likelihood**: Low
**Impact**: Medium
**Mitigation**: Cloud Run provides 99.95% SLA, auto-scaling, and health checks. Implement retry logic in clients. Document operational procedures.

### Risk: Security vulnerabilities
**Likelihood**: Low
**Impact**: High
**Mitigation**: OAuth authentication, Secret Manager for credentials, no credential exposure in responses, regular dependency updates, security audits.

---

## Success Metrics

### Technical Metrics
- Server startup time <5 seconds
- Tool execution latency p95 <5 seconds (excluding long-running audits)
- Error rate <1%
- Test coverage >80%
- Zero security vulnerabilities (Snyk/Dependabot checks)
- Cloud Run cold start <10 seconds

### Business Metrics
- Number of active MCP clients per week
- Tool call volume per week
- User satisfaction (survey-based)
- Cost per audit request <$0.10 (including Cloud Run + BigQuery)
- Time-to-productivity for new users <1 hour

### Operational Metrics
- Deployment success rate >95%
- Mean time to recovery (MTTR) <15 minutes
- Incident count per month <2
- Documentation coverage 100% (all features documented)

---

## Next Steps After Implementation

### Week 1-2: Monitoring and Stabilization
- Monitor production usage patterns
- Fix any bugs or edge cases discovered
- Tune rate limits based on actual usage
- Optimize slow queries identified in metrics

### Month 1: User Feedback and Iteration
- Collect user feedback via surveys
- Iterate on UX based on feedback
- Add missing tools/resources identified by users
- Improve error messages based on support tickets

### Month 2: Feature Expansion
- Add tools for Reddit, Pinterest, TikTok, X adapters (when core adapters are ready)
- Implement resource caching for improved performance
- Add streaming support for long-running operations
- Build custom Claude Skills for common workflows

### Month 3: Advanced Features
- Scheduled audits (cron-triggered via Cloud Scheduler)
- Alerting (push notifications for critical issues)
- Dashboard resources (aggregated metrics over time)
- Multi-region deployment for lower latency

### Ongoing
- Regular security updates
- Performance optimization
- Feature enhancements based on user requests
- Documentation updates

---

## Implementation Timeline

| Phase | Duration | Key Milestones |
|-------|----------|----------------|
| **Phase 1: Local Server** | 1-2 days | STDIO server running, tests passing, Claude Desktop integration verified |
| **Phase 2: Cloud Run** | 2-3 days | Deployed to Cloud Run, OAuth working, remote testing complete |
| **Phase 3: Hardening** | 2-3 days | Monitoring, rate limiting, error handling, runbook validated |
| **Phase 4: Documentation** | 1 day | User guide, API docs, architecture docs complete and reviewed |
| **Total** | **6-9 days** | Production-ready MCP server deployed and documented |

---

## Related Documentation

- [FastMCP Documentation](https://gofastmcp.com/)
- [Model Context Protocol Specification](https://modelcontextprotocol.io/)
- [Google Cloud Run Documentation](https://cloud.google.com/run/docs)
- [PaidSocialNav Core Documentation](../README.md)
- [Architecture Evaluation Research](../research/2025-11-22-claude-skills-mcp-architecture-evaluation.md)

---

## References

### Original Planning Documents
- [Initial Implementation Plan](2025-11-23-fastmcp-remote-server-implementation.md) - Original comprehensive plan
- [Architecture Research](../research/2025-11-22-claude-skills-mcp-architecture-evaluation.md) - Claude Skills vs MCP evaluation

### Code References
**Existing Core (Unchanged)**:
- CLI Entry: `paid_social_nav/cli/main.py`
- Sync Engine: `paid_social_nav/core/sync.py:102`
- Audit Engine: `paid_social_nav/audit/engine.py:46`
- Audit Workflow Skill: `paid_social_nav/skills/audit_workflow.py:22`
- Claude Insights: `paid_social_nav/insights/generator.py:77`
- Tenant Config: `paid_social_nav/core/tenants.py:27`
- BigQuery Client: `paid_social_nav/storage/bq.py:11`

**New MCP Server**:
- Main Server: `mcp_server/server.py`
- Tools: `mcp_server/tools.py`
- Resources: `mcp_server/resources.py`
- Prompts: `mcp_server/prompts.py`
- Error Handling: `mcp_server/error_handling.py`
- Rate Limiting: `mcp_server/rate_limiting.py`
- Monitoring: `mcp_server/monitoring.py`

---

**Document Status**: Ready for Implementation
**Last Updated**: 2025-11-23
**Next Review**: After each phase completion
